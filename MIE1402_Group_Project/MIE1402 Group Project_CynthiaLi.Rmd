---
title: "MIE1402 Group Project Final"
output: html_document
date: "2023-12-13"
---

## Dependencies: installing packages
```{r, warning=FALSE, error=FALSE, message=FALSE}
# install.packages(c('readr', 'dplyr', 'tidyr', 'ggplot2', 'corrr', 'reshape2'))

library(readr)
library(dplyr)     
library(tidyr)      
library(ggplot2)     
library(corrr) 
library(purrr)
library(reshape2)
library(stringr)

```

## Read the CSV file
```{r}
df <- read_csv("data_braintagger_2023.csv", show_col_types = FALSE)
```

```{r}
# Drop the bad hit
df <- df[df$interactionType != "bad hit", ]

# Drop rows where reactionTime < -1
df_cleaned <- df %>%
  filter(reactionTime >= -1)

# Replace reactionTime = -1 with moleDuration
df_cleaned <- df_cleaned %>%
  mutate(reactionTime = ifelse(reactionTime == -1, moleDuration, reactionTime))

# View the cleaned data frame
print(df_cleaned)
```

```{r}
# Define a function to calculate the Z score for a proportion
z_score <- function(p) {
  # Apply continuity correction
  p <- ifelse(p <= 0, .0001, ifelse(p >= 1, .9999, p))
  return(qnorm(p))
}

# Function to calculate D-prime with continuity correction
calculate_d_prime <- function(CHR, FAR) {
  # Apply continuity correction
  CHR <- ifelse(CHR == 0, 0.0001, ifelse(CHR == 1, 0.9999, CHR))
  FAR <- ifelse(FAR == 0, 0.0001, ifelse(FAR == 1, 0.9999, FAR))
  
  # Calculate D-prime
  d_prime <- z_score(CHR) - z_score(FAR)
  return(d_prime)
}

# Step 1: Group by participantNumber and name
# Step 2: Summarize the count of each interactionType
# Step 3, 4, 5: Calculate D-prime or accuracy as needed
# Step 6: Calculate Z-scores for reaction time and score metric
# Step 7: Combine the Z-scores to get a final score
df_summary <- df_cleaned %>%
  group_by(participantNumber, name) %>%
  summarise(
    correct_hit = sum(interactionType == "correct hit"),
    miss = sum(interactionType == "miss"),
    false_alarm = sum(interactionType == "false alarm"),
    correct_rejection = sum(interactionType == "correct rejection"),
    reaction_time = mean(reactionTime, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  rowwise() %>%
  mutate(
    CHR = correct_hit / (correct_hit + miss),
    FAR = false_alarm / (false_alarm + correct_rejection),
    accuracy = correct_hit / (correct_hit + ifelse(grepl("Quick", name), miss, false_alarm)),
    d_prime = ifelse(grepl("Again|Only", name), calculate_d_prime(CHR, FAR), NA_real_),
    accuracy_z = ifelse(grepl("Quick|Bigger|Real|Switch", name), z_score(accuracy), NA_real_),
    score = ifelse(!is.na(d_prime), d_prime, accuracy_z),
  ) %>%
  select(participantNumber, name, score, reaction_time)

# View the summary data frame
print(df_summary)
```

```{r}
# Pivot the table to get each game in columns
df_score <- df_summary %>%
  pivot_wider(
    names_from = name,
    values_from = score,
    id_cols = participantNumber)

# Drop the rows contain any NA and record the participant number
rows_with_na <- which(complete.cases(df_score) == FALSE)
removed_participant_numbers <- df_score[rows_with_na, "participantNumber"]
removed_participant_numbers <- unlist(removed_participant_numbers)

df_score <- na.omit(df_score)

# Scale each column except 'participantNumber'
df_score <- df_score %>%
  mutate(across(-participantNumber, scale))

df_score
```

```{r}
# Pivot the table to get each game in columns
df_reaction <- df_summary %>%
  pivot_wider(
    names_from = name,
    values_from = reaction_time,
    id_cols = participantNumber)

# Drop the rows contain by the recored participant number
df_reaction <- df_reaction[!df_reaction$participantNumber %in% removed_participant_numbers, ]

# Scale each column except 'participantNumber'
df_reaction <- df_reaction %>%
  mutate(across(-participantNumber, scale))

df_reaction
```

```{r}
modify_column <- function(column, column_name, df_reaction) {
  if (str_detect(column_name, "Again") || str_detect(column_name, "Only")) {
    return(column)
  } else {
    return(column - df_reaction[[column_name]])
  }
}

df_final <- df_score %>%
  mutate(across(-participantNumber, 
                .fns = ~ modify_column(., cur_column(), df_reaction)))

names(df_final) <- gsub("\\[, 1\\]", "", names(df_final))
df_final <- df_final %>%
  select(participantNumber, TagMeAgainEasy, TagMeAgainMedium, TagMeAgainHard, TagMeOnly, TagMeQuick, TagMeBigger, TagMeSwitch, PlantMeAgainEasy, PlantMeAgainMedium, PlantMeAgainHard, PlantMeOnly, PlantMeQuick, PlantMeReal, PlantMeSwitch, ShuffleMeOnlyColour, ShuffleMeOnlySuit, ShuffleMeQuick, ShuffleMeBiggerSuit, ShuffleMeBiggerColour, ShuffleMeBiggerAll, ShuffleMeSwitch)

print(df_final)
```

```{r}
# Scale each column except 'participantNumber'
df_final <- df_final %>%
  mutate(across(-participantNumber, scale))

df_final
```

```{r}
# Function to find indices of outliers
find_outlier_indices <- function(column) {
    Q1 <- quantile(column, 0.25, na.rm = TRUE)
    Q3 <- quantile(column, 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    lower_bound <- Q1 - 3 * IQR
    upper_bound <- Q3 + 3 * IQR
    return(which(column < lower_bound | column > upper_bound))
}

# Apply the function to each column and find all outlier indices
outlier_indices_list <- lapply(df_final, find_outlier_indices)

# Combine all outlier indices into one vector
all_outlier_indices <- unique(unlist(outlier_indices_list))

# Remove rows with outliers
df_final <- df_final[-all_outlier_indices, ]

# Print the cleaned data frame
print(df_final)
```


# Question 1.
```{r}
# Exclude the participantNumber column for correlation matrix
cor_matrix <- cor(df_final[, -which(names(df_final) == "participantNumber")], use = "complete.obs")

# View the correlation matrix
print(cor_matrix)
```

```{r}
# Melt the correlation matrix into a long format
melted_cor_matrix <- melt(cor_matrix)

# Plot the heatmap
ggplot(melted_cor_matrix, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "", y = "", title = "Correlation Matrix Heatmap")
```

```{r}
# Find indices of rows and columns that contain "TagMe"
tagme_indices <- grepl("TagMe", rownames(cor_matrix))

# Filter the correlation matrix to keep only those rows and columns
tagme_corr <- cor_matrix[tagme_indices, tagme_indices]
tagme_corr
```
```{r}
# Square each value in the correlation matrix to get the shared variance
tagme_shared_variance <- tagme_corr^2

print(tagme_shared_variance)
```

```{r}
# Initialize a vector to store the average shared variance for each game
tagme_mean_shared_variance <- numeric(nrow(tagme_shared_variance))

# Loop over the rows of the shared variance matrix
for (i in seq_len(nrow(tagme_shared_variance))) {
  # Exclude the shared variance with itself by setting it to NA
  tagme_shared_variance[i, i] <- NA

  # Check if the variable name of the current row contains "Again"
  if (str_detect(rownames(tagme_shared_variance)[i], "Again")) {
    # Calculate the mean excluding columns that contain "Again"
    tagme_mean_shared_variance[i] <- mean(tagme_shared_variance[i, !str_detect(colnames(tagme_shared_variance), "Again")], na.rm = TRUE)
  } else {
    # Calculate the mean including all columns
    tagme_mean_shared_variance[i] <- mean(tagme_shared_variance[i, ], na.rm = TRUE)
  }
}


# Prepare the final dataframe
tagme_mean_shared_variance <- data.frame(
  game_name = gsub("TagMe", "", rownames(tagme_shared_variance)),
  tagme_mean_shared_variance = tagme_mean_shared_variance)

tagme_mean_shared_variance
```


```{r}
# Find indices of rows and columns that contain "PlantMe"
plantme_indices <- grepl("PlantMe", rownames(cor_matrix))

# Filter the correlation matrix to keep only those rows and columns
plantme_corr <- cor_matrix[plantme_indices, plantme_indices]

# Square each value in the correlation matrix to get the shared variance
plantme_shared_variance <- plantme_corr^2

print(plantme_shared_variance)
```

```{r}
# Initialize a vector to store the average shared variance for each game
plantme_mean_shared_variance <- numeric(nrow(plantme_shared_variance))

# Loop over the rows of the shared variance matrix
for (i in seq_len(nrow(plantme_shared_variance))) {
  # Exclude the shared variance with itself by setting it to NA
  plantme_shared_variance[i, i] <- NA

  # Check if the variable name of the current row contains "Again"
  if (str_detect(rownames(plantme_shared_variance)[i], "Again")) {
    # Calculate the mean excluding columns that contain "Again"
    plantme_mean_shared_variance[i] <- mean(plantme_shared_variance[i, !str_detect(colnames(plantme_shared_variance), "Again")], na.rm = TRUE)
  } else {
    # Calculate the mean including all columns
    plantme_mean_shared_variance[i] <- mean(plantme_shared_variance[i, ], na.rm = TRUE)
  }
}

# Prepare the final dataframe
plantme_mean_shared_variance <- data.frame(
  game_name = gsub("PlantMe", "", rownames(plantme_shared_variance)),
  plantme_mean_shared_variance = plantme_mean_shared_variance)

plantme_mean_shared_variance
```

```{r}
# Find indices of rows and columns that contain "ShuffleMe"
shuffleme_indices <- grepl("ShuffleMe", rownames(cor_matrix))

# Filter the correlation matrix to keep only those rows and columns
shuffleme_corr <- cor_matrix[shuffleme_indices, shuffleme_indices]

# Square each value in the correlation matrix to get the shared variance
shuffleme_shared_variance <- shuffleme_corr^2

print(shuffleme_shared_variance)
```

```{r}
# Initialize a vector to store the average shared variance for each game
shuffleme_mean_shared_variance <- numeric(nrow(shuffleme_shared_variance))

# Loop over the rows of the shared variance matrix
for (i in seq_len(nrow(shuffleme_shared_variance))) {
  # Exclude the shared variance with itself by setting it to NA
  shuffleme_shared_variance[i, i] <- NA

  # Check if the variable name of the current row contains "Bigger"
  if (str_detect(rownames(shuffleme_shared_variance)[i], "Bigger")) {
    # Calculate the mean excluding columns that contain "Bigger"
    shuffleme_mean_shared_variance[i] <- mean(shuffleme_shared_variance[i, !str_detect(colnames(shuffleme_shared_variance), "Bigger")], na.rm = TRUE)
  } else {
    if (str_detect(rownames(shuffleme_shared_variance)[i], "Only")){
      shuffleme_mean_shared_variance[i] <- mean(shuffleme_shared_variance[i, !str_detect(colnames(shuffleme_shared_variance), "Only")], na.rm = TRUE)
    } else {
    # Calculate the mean including all columns
    shuffleme_mean_shared_variance[i] <- mean(shuffleme_shared_variance[i, ], na.rm = TRUE)}
  }
}

# Prepare the final dataframe
shuffleme_mean_shared_variance <- data.frame(
  game_name = gsub("ShuffleMe", "", rownames(shuffleme_shared_variance)),
  shuffleme_mean_shared_variance = shuffleme_mean_shared_variance)

shuffleme_mean_shared_variance
```

```{r}
# Function to rename "Real" to "Bigger" and set row index as a column "game_name"
prepare_df_for_merge <- function(df) {
  df$game_name <- gsub("Real", "Bigger", df$game_name)
  return(df)
}

# Apply the function to each dataframe
tagme_prepared <- prepare_df_for_merge(tagme_mean_shared_variance)
plantme_prepared <- prepare_df_for_merge(plantme_mean_shared_variance)
shuffleme_prepared <- prepare_df_for_merge(shuffleme_mean_shared_variance)

# Merge the data frames
mean_shared_variance <- merge(tagme_prepared, plantme_prepared, by = "game_name", all = TRUE)
mean_shared_variance <- merge(mean_shared_variance, shuffleme_prepared, by = "game_name", all = TRUE)

# Rename the columns for clarity
names(mean_shared_variance) <- c("Game", "TagMe", "PlantMe", "ShuffleMe")
rownames(mean_shared_variance) <- mean_shared_variance$Game
mean_shared_variance$Game <- NULL

# Check the result
print(mean_shared_variance)
```

# Question 2.
```{r}
# Find indices of rows and columns that contain "Only"
only_indices <- grepl("Only", rownames(cor_matrix))

# Filter the correlation matrix to keep only those rows and columns
only_corr <- cor_matrix[only_indices, only_indices]
only_corr
```

```{r}
# Find indices of rows and columns that contain "Quick"
quick_indices <- grepl("Quick", rownames(cor_matrix))

# Filter the correlation matrix to keep only those rows and columns
quick_corr <- cor_matrix[quick_indices, quick_indices]
quick_corr
```

```{r}
# Find indices of rows and columns that contain "Bigger"
bigger_indices <- grepl("Bigger|Real", rownames(cor_matrix))

# Filter the correlation matrix to keep only those rows and columns
bigger_corr <- cor_matrix[bigger_indices, bigger_indices]
bigger_corr
```

```{r}
# Find indices of rows and columns that contain "Switch"
switch_indices <- grepl("Switch", rownames(cor_matrix))

# Filter the correlation matrix to keep only those rows and columns
switch_corr <- cor_matrix[switch_indices, switch_indices]
switch_corr
```
# Question 3.
```{r}
# Extract only the games
df_cluster <- df_final[, -1]
names(df_cluster) <- gsub("\\[, 1\\]", "", names(df_cluster))

# Compute the Distance Matrix
dist_matrix <- dist(t(df_cluster), method = "euclidean")

# Apply Hierarchical Clustering with average linkage
hc <- hclust(dist_matrix, method = "average")

# Visualize with a Dendrogram
plot(hc, main = "Dendrogram using Average Linkage", xlab = "Questions", sub = "", cex = 0.9)
rect.hclust(hc, k=10, border = 'red')
```

```{r}
#K-means and plot
kmeans_result <- kmeans(t(df_cluster), centers=2)
fviz_cluster(list(data=t(df_cluster), cluster = kmeans_result$cluster), plaette='jco', stand = FALSE, ggtheme=theme_classic())

#Print a table to see cluster labels clearly
cluster_group <- data.frame(Game = rownames(t(df_cluster)), 
                                 Cluster = kmeans_result$cluster)
print(cluster_group)
```
```{r}
# Melting the dataframe
df_long <- melt(df_final, id.vars = "participantNumber", variable.name = "GameSkin", value.name = "Score")

# Extracting Skin Type and Game Name
# Adjusting the regular expression to handle cases like "PlantMeAgainMedium"
df_long$Skin <- gsub("(.*?Me)(?!Me).*", "\\1", df_long$GameSkin, perl = TRUE)
df_long$Game <- gsub(".*?Me(?!Me)(.*)", "\\1", df_long$GameSkin, perl = TRUE)

# Dropping the original 'GameSkin' column as it's no longer needed
df_long$GameSkin <- NULL
df_long$Game <- ifelse(df_long$Game == "Real", "Bigger", df_long$Game)

# View the transformed data
df_long
```

```{r}
library(ez)

# Conducting Repeated Measures Factorial ANOVA
anova_results <- ezANOVA(
  data = df_long,
  dv = .(Score),              # Dependent variable
  wid = .(participantNumber), # Participant ID
  within = .(Skin, Game),     # Within-subjects factors
  detailed = TRUE,            # Request detailed output
  type = 3                    # Type of sums of squares to use
)

# Viewing the results
anova_results
```

```{r}
library(lme4)
library(lmerTest)

model <- lmer(Score ~ Game * Skin + (1|participantNumber), data = df_long)
summary(model)
```









